{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "682d5e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession \\\n",
    "        .builder \\\n",
    "        .master('local') \\\n",
    "        .appName('Capstone') \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bcafecd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.1.2'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5c2b9278",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, MapType, TimestampType, DoubleType, BooleanType\n",
    "\n",
    "clickstream_schema = StructType([\n",
    "    StructField(\"userId\", StringType(), True),\n",
    "    StructField(\"eventId\", StringType(), True),\n",
    "    StructField(\"eventType\", StringType(), True),\n",
    "    StructField(\"eventTime\", TimestampType(), True),\n",
    "    StructField(\"attributes\", StringType(), True)\n",
    "  ])\n",
    "purchases_schema = StructType([\n",
    "    StructField(\"purchaseId\", StringType(), True),\n",
    "    StructField(\"purchaseTime\", TimestampType(),True),\n",
    "    StructField(\"billingCost\", DoubleType(), True),\n",
    "    StructField(\"isConfirmed\", BooleanType(), True)\n",
    "  ])\n",
    "\n",
    "clickstream_raw_df = spark.read \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .schema(clickstream_schema) \\\n",
    "                    .csv(\"capstone-dataset/mobile_app_clickstream/*.gz\")\n",
    "purchases_df = spark.read \\\n",
    "                    .option(\"header\", \"true\") \\\n",
    "                    .schema(purchases_schema) \\\n",
    "                    .csv(\"capstone-dataset/user_purchases/*.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f9dacb12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- eventId: string (nullable = true)\n",
      " |-- eventType: string (nullable = true)\n",
      " |-- eventTime: timestamp (nullable = true)\n",
      " |-- attributes: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pyspark.sql.functions import udf\n",
    "\n",
    "def to_map_type(value):\n",
    "    if value:\n",
    "        try:\n",
    "            return json.loads(value.replace('\\'', '\"'))\n",
    "        except json.JSONDecodeError:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "to_map_udf = udf(to_map_type, MapType(StringType(), StringType()))\n",
    "\n",
    "clickstream_df = clickstream_raw_df.withColumn('attributes', to_map_udf('attributes'))\n",
    "\n",
    "clickstream_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "79538ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- userId: string (nullable = true)\n",
      " |-- eventId: string (nullable = true)\n",
      " |-- eventType: string (nullable = true)\n",
      " |-- eventTime: timestamp (nullable = true)\n",
      " |-- attributes: map (nullable = true)\n",
      " |    |-- key: string\n",
      " |    |-- value: string (valueContainsNull = true)\n",
      " |-- sessionInfo: struct (nullable = true)\n",
      " |    |-- sessionId: string (nullable = false)\n",
      " |    |-- campaignId: string (nullable = false)\n",
      " |    |-- channelId: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import last\n",
    "\n",
    "def generate_session_id(user_id, event_time, event_type, attributes):\n",
    "    if event_type == 'app_open':\n",
    "        try:\n",
    "            session_id = f'{user_id}_{event_time.timestamp()}'\n",
    "            campaign_id = attributes['campaign_id']\n",
    "            channel_id = attributes['channel_id']\n",
    "            return session_id, campaign_id, channel_id\n",
    "        except Exception:\n",
    "            return None\n",
    "    return None\n",
    "\n",
    "udf_schema = StructType([\n",
    "    StructField('sessionId', StringType(), False),\n",
    "    StructField('campaignId', StringType(), False),\n",
    "    StructField('channelId', StringType(), False)\n",
    "])\n",
    "generate_session_udf = udf(generate_session_id, udf_schema)\n",
    "\n",
    "def add_session_column(input_df):\n",
    "    w = Window.partitionBy('userId').orderBy('eventTime')\n",
    "    \n",
    "    return input_df \\\n",
    "            .withColumn('sessionInfo', generate_session_udf('userId', 'eventTime', 'eventType', 'attributes')) \\\n",
    "            .withColumn('sessionInfo', last('sessionInfo', True).over(w))\n",
    "\n",
    "clicks_sess_df = add_session_column(clickstream_df)\n",
    "clicks_sess_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "442856f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- purchaseId: string (nullable = true)\n",
      " |-- purchaseTime: timestamp (nullable = true)\n",
      " |-- billingCost: double (nullable = true)\n",
      " |-- isConfirmed: boolean (nullable = true)\n",
      " |-- sessionId: string (nullable = true)\n",
      " |-- campaignId: string (nullable = true)\n",
      " |-- channelId: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "purchases_clicks_df = clicks_sess_df.filter(clicks_sess_df.eventType == 'purchase')\n",
    "\n",
    "purchases_projection_df = purchases_df \\\n",
    "                            .join(purchases_clicks_df, \n",
    "                                  purchases_df.purchaseId == purchases_clicks_df.attributes['purchase_id']) \\\n",
    "                            .select(purchases_df.purchaseId, \n",
    "                                    purchases_df.purchaseTime,\n",
    "                                    purchases_df.billingCost,\n",
    "                                    purchases_df.isConfirmed,\n",
    "                                    purchases_clicks_df.sessionInfo.sessionId.alias('sessionId'),\n",
    "                                    purchases_clicks_df.sessionInfo.campaignId.alias('campaignId'),\n",
    "                                    purchases_clicks_df.sessionInfo.channelId.alias('channelId'))\n",
    "\n",
    "purchases_projection_df.printSchema()\n",
    "purchases_projection_df.createOrReplaceTempView('purchases_projection')\n",
    "spark.catalog.cacheTable('purchases_projection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "85bf97f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------------+\n",
      "|campaignId|           revenue|\n",
      "+----------+------------------+\n",
      "|       190|2041060.8400000012|\n",
      "|       528|1510378.1599999997|\n",
      "|       325|1470622.3199999996|\n",
      "|       585|        1047838.02|\n",
      "|       779|1031561.1399999999|\n",
      "|       650|1031403.1300000004|\n",
      "|       859|1024151.6600000001|\n",
      "|       610|1020675.5800000003|\n",
      "|       669|1019272.5699999997|\n",
      "|       461|1018971.0200000006|\n",
      "+----------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_campaigns_df = spark.sql(\"\"\"\n",
    "    SELECT campaignId, sum(billingCost) as revenue FROM purchases_projection\n",
    "    WHERE isConfirmed\n",
    "    GROUP BY campaignId\n",
    "    ORDER BY sum(billingCost) DESC\n",
    "    LIMIT 10\n",
    "\"\"\")\n",
    "\n",
    "top_campaigns_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3cdface8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+------------+--------------+\n",
      "|campaignId|   channelId|uniqueSessions|\n",
      "+----------+------------+--------------+\n",
      "|       766|      VK Ads|           419|\n",
      "|       350|      VK Ads|           425|\n",
      "|       823|Facebook Ads|           428|\n",
      "|       451|  Yandex Ads|           821|\n",
      "|       271|  Yandex Ads|           417|\n",
      "|       747| Twitter Ads|           409|\n",
      "|       888|Facebook Ads|           399|\n",
      "|       963|  Google Ads|           406|\n",
      "|       604|  Google Ads|           408|\n",
      "|       924| Twitter Ads|           432|\n",
      "|       833|  Yandex Ads|           457|\n",
      "|       538| Twitter Ads|           422|\n",
      "|       502|Facebook Ads|           408|\n",
      "|       734|  Yandex Ads|           418|\n",
      "|       262| Twitter Ads|           400|\n",
      "|       998|  Yandex Ads|           415|\n",
      "|       911|Facebook Ads|           414|\n",
      "|       611|  Google Ads|           421|\n",
      "|       298|      VK Ads|           815|\n",
      "|       695| Twitter Ads|           400|\n",
      "+----------+------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "most_popular_channels_df = spark.sql(\"\"\"\n",
    "    WITH channelStatistics as (\n",
    "        SELECT campaignId, channelId, count(DISTINCT sessionId) as uniqueSessions FROM purchases_projection\n",
    "        GROUP BY campaignId, channelId\n",
    "    )\n",
    "    SELECT cs.campaignId, cs.channelId, maxcs.uniqueSessions FROM channelStatistics as cs\n",
    "    INNER JOIN (\n",
    "        SELECT campaignId, max(uniqueSessions) as uniqueSessions FROM channelStatistics GROUP BY campaignId\n",
    "    ) as maxcs\n",
    "    ON cs.uniqueSessions = maxcs.uniqueSessions \n",
    "        AND cs.campaignId = maxcs.campaignId\n",
    "\"\"\")\n",
    "\n",
    "most_popular_channels_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "34d36e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "purchases_projection_df.write.parquet(\"results/purchases_projection.parquet\")\n",
    "top_campaigns_df.write.parquet(\"results/top_campaigns.parquet\")\n",
    "most_popular_channels_df.write.parquet(\"results/most_popular_channels.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "27cdbda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_map_type_correct_input_single_quotes():\n",
    "    test_value = \"{'a': 'b'}\"\n",
    "    result = to_map_type(test_value)\n",
    "    expected = {'a': 'b'}\n",
    "    assert result == expected\n",
    "    \n",
    "test_to_map_type_correct_input_single_quotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "338cfbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_map_type_correct_input_double_quotes():\n",
    "    test_value = '{\"a\": \"b\"}'\n",
    "    result = to_map_type(test_value)\n",
    "    expected = {'a': 'b'}\n",
    "    assert result == expected\n",
    "    \n",
    "test_to_map_type_correct_input_double_quotes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a47ac580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_map_type_null_input():\n",
    "    test_value = None\n",
    "    result = to_map_type(test_value)\n",
    "    expected = None\n",
    "    assert result == expected\n",
    "    \n",
    "test_to_map_type_null_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c71362fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_to_map_type_incorrect_input():\n",
    "    test_value = \"{'a': }\"\n",
    "    result = to_map_type(test_value)\n",
    "    expected = None\n",
    "    assert result == expected\n",
    "    \n",
    "test_to_map_type_incorrect_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50829dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generate_session_id_correct_input():\n",
    "    from datetime import datetime\n",
    "    test_user_id = 1\n",
    "    test_event_time = datetime(2021, 1, 1)\n",
    "    test_event_type = 'app_open'\n",
    "    test_attributes = {'campaign_id': 1, 'channel_id': 2}\n",
    "    result = generate_session_id(test_user_id, test_event_time, test_event_type, test_attributes)\n",
    "    expected = f'1_{test_event_time.timestamp()}', 1, 2\n",
    "    assert result == expected\n",
    "    \n",
    "test_generate_session_id_correct_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a2a370f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generate_session_id_incorrect_input():\n",
    "    from datetime import datetime\n",
    "    test_user_id = 1\n",
    "    test_event_time = None\n",
    "    test_event_type = 'app_open'\n",
    "    test_attributes = None\n",
    "    result = generate_session_id(test_user_id, test_event_time, test_event_type, test_attributes)\n",
    "    expected = None\n",
    "    assert result == expected\n",
    "    \n",
    "test_generate_session_id_incorrect_input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3042f878",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_generate_session_id_wrong_event_type():\n",
    "    from datetime import datetime\n",
    "    test_user_id = 1\n",
    "    test_event_time = datetime(2021, 1, 1)\n",
    "    test_event_type = 'app_close'\n",
    "    test_attributes = {'campaign_id': 1, 'channel_id': 2}\n",
    "    result = generate_session_id(test_user_id, test_event_time, test_event_type, test_attributes)\n",
    "    expected = None\n",
    "    assert result == expected\n",
    "    \n",
    "test_generate_session_id_wrong_event_type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "de332c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assert_frame_equal_with_sort(results, expected, keycolumns):\n",
    "    from pandas.testing import assert_frame_equal\n",
    "    \n",
    "    results_sorted = results.sort_values(by=keycolumns).reset_index(drop=True)\n",
    "    expected_sorted = expected.sort_values(by=keycolumns).reset_index(drop=True)\n",
    "    assert_frame_equal(results_sorted, expected_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "5d092043",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_add_session_column():\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "\n",
    "    test_data = {\n",
    "            'userId': [1, 1, 2, 2, 2, 2],\n",
    "            'eventId': [1, 2, 3, 4, 5, 6],\n",
    "            'eventType': ['app_open', 'app_close'] * 3,\n",
    "            'eventTime': [datetime(2020, 1, 1), datetime(2020, 1, 2), datetime(2020, 1, 3),\n",
    "                         datetime(2020, 1, 4), datetime(2020, 1, 5), datetime(2020, 1, 6)],\n",
    "            'attributes': [{'campaign_id': '332', 'channel_id': 'Facebook Ads'}, None] * 3\n",
    "    }\n",
    "    test_pd_df = pd.DataFrame(test_data)\n",
    "\n",
    "    test_df = spark.createDataFrame(test_pd_df)\n",
    "    result_df = add_session_column(test_df)\n",
    "    result_pd_df = result_df.toPandas()\n",
    "\n",
    "    expected_data = test_data.copy()\n",
    "    expected_data['sessionInfo'] = [\n",
    "        ('1_1577836800.0', '332', 'Facebook Ads'),\n",
    "        ('1_1577836800.0', '332', 'Facebook Ads'),\n",
    "        ('2_1578009600.0', '332', 'Facebook Ads'),\n",
    "        ('2_1578009600.0', '332', 'Facebook Ads'),\n",
    "        ('2_1578182400.0', '332', 'Facebook Ads'),\n",
    "        ('2_1578182400.0', '332', 'Facebook Ads'),\n",
    "    ]\n",
    "    expected_pd_df = pd.DataFrame(expected_data)\n",
    "    assert_frame_equal_with_sort(result_pd_df, expected_pd_df, ['eventTime'])\n",
    "    \n",
    "test_add_session_column()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da833a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
